{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN for Sentence Generation",
      "provenance": [],
      "authorship_tag": "ABX9TyMXSSMvS6pyPl0s2w47RZwm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PamelaVQ/Base-ML/blob/master/Pytorch_Basics/RNN_for_Sentence_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjupPDxyIRii",
        "colab_type": "text"
      },
      "source": [
        "Use Recurrent Neural Network for Sentence Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1D8b1g6Ilo3",
        "colab_type": "text"
      },
      "source": [
        "Reference Links:\n",
        "\n",
        "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "https://gist.github.com/karpathy/d4dee566867f8291f086\n",
        "\n",
        "https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml6VEf0qII-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "import io\n",
        "import sklearn\n",
        "import sklearn.feature_extraction\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torch"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0UdMkKdM28A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pattern_text(start_pattern, end_pattern, data):\n",
        "  # pattern = f'{start_pattern}(.*){end_pattern}'\n",
        "  # result = re.search(re.escape(pattern), data)\n",
        "  result = data[data.find(start_pattern)+len(start_pattern):data.rfind(end_pattern)]\n",
        "  return result"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaMK09OcLZZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = get_file(\"agatha_christie\", origin=\"https://www.gutenberg.org/files/863/863-0.txt\")\n",
        "with io.open(path, encoding='utf-8') as read_file:\n",
        "  data_agatha_christie = read_file.readlines()\n",
        "# start_text = \"\"\"*** START OF THIS PROJECT GUTENBERG EBOOK THE MYSTERIOUS AFFAIR AT STYLES ***\"\"\".lower()\n",
        "# end_text = \"\"\"*** END OF THIS PROJECT GUTENBERG EBOOK THE MYSTERIOUS AFFAIR AT STYLES ***\"\"\".lower()\n",
        "# data_agatha_christie = pattern_text(start_text, end_text, data)\n",
        "# print(f'agatha_christie corpus length:{len(data_agatha_christie)}')\n",
        "\n",
        "path = get_file(\"lewis_carroll\", origin=\"https://www.gutenberg.org/files/11/11-0.txt\")\n",
        "with io.open(path, encoding='utf-8') as read_file:\n",
        "  data_lewis_carroll = read_file.readlines()\n",
        "# start_text = \"\"\"*** START OF THIS PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\"\"\".lower()\n",
        "# end_text = \"\"\"*** END OF THIS PROJECT GUTENBERG EBOOK ALICE’S ADVENTURES IN WONDERLAND ***\"\"\".lower()\n",
        "# data_lewis_carroll = pattern_text(start_text, end_text, data)\n",
        "# print(f'lewis_carroll corpus length:{len(data_lewis_carroll)}')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Cu2ZsxNmMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverse_dictionary(my_map):\n",
        "  return {v: k for k, v in my_map.items()}\n",
        "\n",
        "def create_vocab(corpus):\n",
        "  # corpus = [x for x in data if len(x)>0]\n",
        "  vectorizer = sklearn.feature_extraction.text.CountVectorizer(min_df=1)\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "  analyzer = vectorizer.build_analyzer()\n",
        "  output_corpus = [x for x in [list(map(lambda x: vectorizer.vocabulary_.get(x), analyzer(line))) for line in corpus] if x]\n",
        "  word2idx = vectorizer.vocabulary_\n",
        "  # print(f'word2idx: {word2idx}')\n",
        "  idx2word = reverse_dictionary(word2idx)\n",
        "  # print(f'idx2word: {idx2word}')\n",
        "  return word2idx, idx2word, output_corpus\n",
        "\n",
        "word2idx, idx2word, output_corpus = create_vocab(data_agatha_christie)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQoEdHqeifZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vocab_details(corpus):\n",
        "  max_length = max([len(corpus) for corpus in corpus])\n",
        "  vocab_size = len(corpus)\n",
        "  return max_length, vocab_size\n",
        "\n",
        "max_length, vocab_size = get_vocab_details(output_corpus)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL5lnTPEWfpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, max_length, vocab_size):\n",
        "      super(RNN, self).__init__()\n",
        "      # self.embed = nn.Embedding(input_size, 128)\n",
        "      self.lstm = nn.LSTM(128, input_shape=(max_length, vocab_size))\n",
        "      self.dense = nn.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.lstm(x)\n",
        "      x = self.dense(x)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2gBL-l54q5_",
        "colab_type": "text"
      },
      "source": [
        "Understanding LSTM: [Pytorch LSTM Docs](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuH0uJ5ApiLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3976a1f8-28a2-453a-991a-7b20ccd466a9"
      },
      "source": [
        "# testing LSTM\n",
        "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
        "print(inputs[0].shape)\n",
        "# initialize the hidden state.\n",
        "hidden = (torch.randn(1, 1, 3),\n",
        "          torch.randn(1, 1, 3))\n",
        "print(hidden)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3])\n",
            "(tensor([[[-0.1148, -0.0082,  0.7596]]]), tensor([[[0.2458, 0.3851, 2.0894]]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ABOjipVsxB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in inputs:\n",
        "    # Step through the sequence one element at a time.\n",
        "    # after each step, hidden contains the hidden state.\n",
        "    out, hidden = lstm(i.view(1, 1, -1), hidden) # (3,3) ((3,3), (3,3))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwZuoiQIxxtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "16cfc075-f632-4968-d34c-46359e548840"
      },
      "source": [
        "# do all 3 inputs at once\n",
        "inputs_1 = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
        "output, hidden = lstm(inputs_1, hidden)\n",
        "print(output.shape)\n",
        "print(hidden[0].shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 3])\n",
            "torch.Size([1, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZeQiRi24W7v",
        "colab_type": "text"
      },
      "source": [
        "Learning: [An LSTM for Part-of-Speech Tagging](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#example-an-lstm-for-part-of-speech-tagging)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0umcTj9B0dQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}